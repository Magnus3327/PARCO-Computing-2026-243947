/*
Considerazioni sulla parallelizzazione della SpMV con OpenMP:
Allora potrei parallelizzare normalmente il ciclo esterno (sulle righe), ogni thread calcola la somma per una riga diversa.
Questo funziona bene perché ogni thread scrive in una posizione diversa dell'array di output y, quindi non ci sono conflitti di scrittura.
Ma non sappiamo se l'accesso alla memoria per csr.data e csr.indices sarà ottimale, perché diversi thread potrebbero accedere a posizioni di memoria non contigue.
Per migliorare la località della cache, potremmo considerare di riorganizzare i dati in modo che gli accessi siano più sequenziali.
C'è anche il problema del bilanciamento del carico: se alcune righe hanno molti più elementi non zero rispetto ad altre, alcuni thread potrebbero finire molto prima di altri, lasciando i core inattivi.
Una soluzione potrebbe essere quella di dividere il lavoro in blocchi più piccoli, in modo che i thread possano prendere nuovi blocchi di lavoro quando finiscono i loro.
Inoltre, dobbiamo assicurarci che la somma parziale per ogni riga sia calcolata correttamente senza condizioni di gara.
Si potrebbe usare una variabile temporanea per ogni thread per accumulare la somma prima di scriverla nell'array di output y.
Quindi ricapitolando, la parallelizzazione del ciclo esterno è una buona strategia, ma dobbiamo considerare attentamente l'accesso alla memoria, il bilanciamento del carico e la gestione delle somme parziali per garantire un'implementazione efficiente e corretta.
Anche lo scheduling dinamico potrebbe essere utile per bilanciare il carico tra i thread.
Altri problemi potrebbero includere l'overhead di creazione e gestione dei thread, che potrebbe essere significativo per matrici molto piccole.
Dobbiamo anche usare il giusto numero di thread in base al numero di core disponibili sulla macchina per evitare il sovraccarico.
ma invece di usare direttamente 64 chucnks non lo si puo fare in base al nnz e ai threads disponibili?
*/

1. Modularità e riusabilità
	•	Tutte le operazioni su CSR (memoria, SpMV, stampa, ecc.) sono centralizzate in un oggetto o libreria.
	•	Funzioni generiche (lettura MTX, generazione vettori, JSON output) sono separate dal main.
	•	Facilita l’uso dello stesso codice sia in modalità sequenziale sia parallela senza duplicazioni.

2. Manutenzione e leggibilità
	•	Il main diventa un semplice orchestratore, più leggibile.
	•	Separazione chiara tra I/O, gestione parametri e logica di calcolo.
	•	Riduce il rischio di confusione quando si aggiungono nuove funzionalità.

3. Sicurezza e gestione memoria
	•	Oggetti con costruttore/distruttore riducono i memory leak.
	•	Non serve fare delete[] manuali ovunque nel main.
	•	Error handling centralizzato tramite throw + try/catch.

4. Estensibilità
	•	Facile aggiungere nuove funzioni (es. operazioni sparse-sparse, diverse routine parallele).
	•	Nuove modalità (scheduling OpenMP, chunk size, numero di thread) possono essere aggiunte senza modificare il main.

5. Preparazione HPC e scripting
	•	Parametri runtime (threads, scheduling, chunk size, iterazioni) gestiti in modo uniforme.
	•	Supporta warm-up e iterazioni multiple senza modificare il codice.
	•	Facilita creare script PBS o bash per lanciare decine di combinazioni.

6. Valutazione accademica e professionale
	•	Codice modulare e leggibile è percepito come più professionale.
	•	Migliore gestione della memoria e della struttura del progetto è apprezzata dai docenti.
	•	Consente di consegnare un workflow chiaro, facilmente testabile e replicabile.