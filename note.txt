/*
Considerazioni sulla parallelizzazione della SpMV con OpenMP:
Allora potrei parallelizzare normalmente il ciclo esterno (sulle righe), ogni thread calcola la somma per una riga diversa.
Questo funziona bene perché ogni thread scrive in una posizione diversa dell'array di output y, quindi non ci sono conflitti di scrittura.
Ma non sappiamo se l'accesso alla memoria per csr.data e csr.indices sarà ottimale, perché diversi thread potrebbero accedere a posizioni di memoria non contigue.
Per migliorare la località della cache, potremmo considerare di riorganizzare i dati in modo che gli accessi siano più sequenziali.
C'è anche il problema del bilanciamento del carico: se alcune righe hanno molti più elementi non zero rispetto ad altre, alcuni thread potrebbero finire molto prima di altri, lasciando i core inattivi.
Una soluzione potrebbe essere quella di dividere il lavoro in blocchi più piccoli, in modo che i thread possano prendere nuovi blocchi di lavoro quando finiscono i loro.
Inoltre, dobbiamo assicurarci che la somma parziale per ogni riga sia calcolata correttamente senza condizioni di gara.
Si potrebbe usare una variabile temporanea per ogni thread per accumulare la somma prima di scriverla nell'array di output y.
Quindi ricapitolando, la parallelizzazione del ciclo esterno è una buona strategia, ma dobbiamo considerare attentamente l'accesso alla memoria, il bilanciamento del carico e la gestione delle somme parziali per garantire un'implementazione efficiente e corretta.
Anche lo scheduling dinamico potrebbe essere utile per bilanciare il carico tra i thread.
Altri problemi potrebbero includere l'overhead di creazione e gestione dei thread, che potrebbe essere significativo per matrici molto piccole.
Dobbiamo anche usare il giusto numero di thread in base al numero di core disponibili sulla macchina per evitare il sovraccarico.
ma invece di usare direttamente 64 chucnks non lo si puo fare in base al nnz e ai threads disponibili?
*/

